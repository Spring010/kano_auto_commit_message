import json


def main():
    with open('kano_py_tokenizer.json', 'r') as f:
        input_json = json.load(f)
    model = input_json['model']
    vocab = model['vocab']
    remove_list = [
        '=========================================================================',
        '##--------------------------------',
        '---------------------------------',
        '-----------------',
        '##----------------------------------------------------------------',
        '##****************',
        '##----------------',
        '##********************************',
        '##________________',
        '##================================================================',
        '------------',
        '##------------',
        '##================',
        '##~~~~~~~~~~~~~~~~',
        '##================================',
        '##+--------',
        '-----------------------------------------------------------------',
        '----------------------------------------',
        '---------------',
        '-------------------------------------------------------------------------',
        '----------------------------------------------------------------------',
        '=================================================================',
        '##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~',
        '-------------------------',
        '##------------------------',
        '##................',
    ]
    for remove in remove_list:
        vocab[remove] = vocab[model['unk_token']]
    with open('kano_py_tokenizer_clean.json', 'w') as f:
        json.dump(input_json, f)


if __name__ == '__main__':
    main()
